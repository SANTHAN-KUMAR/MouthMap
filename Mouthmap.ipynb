{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tqdm.keras import TqdmCallback  \n",
    "import datetime\n",
    "\n",
    "\n",
    "class LipReadingDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data_path, alignment_path, batch_size=32, frame_length=75, \n",
    "                 image_height=46, image_width=140, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data_path = data_path\n",
    "        self.alignment_path = alignment_path\n",
    "        self.batch_size = batch_size\n",
    "        self.frame_length = frame_length\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "\n",
    "        self.video_paths = sorted(glob(os.path.join(data_path, '*.mpg')))\n",
    "        self.alignment_paths = sorted(glob(os.path.join(alignment_path, '*.align')))\n",
    "        \n",
    "        print(f\"Found {len(self.video_paths)} video files and {len(self.alignment_paths)} alignment files\")\n",
    "        self.vocabulary = self._create_word_vocabulary()\n",
    "            \n",
    "        self.char_to_num = tf.keras.layers.StringLookup(\n",
    "            vocabulary=self.vocabulary, oov_token=\"\")\n",
    "        self.num_to_char = tf.keras.layers.StringLookup(\n",
    "            vocabulary=self.vocabulary, oov_token=\"\", invert=True)\n",
    "    \n",
    "    def _create_word_vocabulary(self):\n",
    "        words = set()\n",
    "        print(f\"Processing alignment files from: {self.alignment_path}\")\n",
    "        \n",
    "        for align_path in self.alignment_paths:\n",
    "            try:\n",
    "                with open(align_path, 'r') as f:\n",
    "                    content = f.read().strip().split()\n",
    "                    words.update([content[i] for i in range(2, len(content), 3)])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {align_path}: {str(e)}\")\n",
    "        \n",
    "        words.discard('sil')\n",
    "        vocabulary = sorted(list(words))\n",
    "        \n",
    "        if not vocabulary:\n",
    "            print(\"No words found in alignment files. Using default vocabulary.\")\n",
    "            vocabulary = ['bin', 'blue', 'at', 'f', 'two', 'now']\n",
    "        \n",
    "        print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "        return vocabulary\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(1, len(self.video_paths) // self.batch_size)\n",
    "    \n",
    "    def _process_video(self, video_path):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            mouth = gray[190:236, 80:220]\n",
    "            mouth = cv2.resize(mouth, (self.image_width, self.image_height))\n",
    "            frames.append(mouth)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        frames = np.array(frames, dtype=np.float32)\n",
    "        frames = (frames - frames.mean()) / (frames.std() + 1e-6)\n",
    "        \n",
    "        if len(frames) < self.frame_length:\n",
    "            pad_length = self.frame_length - len(frames)\n",
    "            frames = np.pad(frames, ((0, pad_length), (0, 0), (0, 0)), mode='constant')\n",
    "        else:\n",
    "            frames = frames[:self.frame_length]\n",
    "        \n",
    "        return frames\n",
    "    \n",
    "    def _process_alignment(self, alignment_path):\n",
    "        with open(alignment_path, 'r') as f:\n",
    "            content = f.read().strip().split()\n",
    "        \n",
    "        words = [content[i] for i in range(2, len(content), 3) if content[i] != 'sil']\n",
    "        text = ' '.join(words)\n",
    "        return self.char_to_num(tf.convert_to_tensor(text.split()))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_videos = self.video_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_alignments = self.alignment_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        X = np.zeros((len(batch_videos), self.frame_length, self.image_height, self.image_width, 1))\n",
    "        Y = np.zeros((len(batch_videos), len(self.vocabulary)))\n",
    "        \n",
    "        for i, (video_path, align_path) in enumerate(zip(batch_videos, batch_alignments)):\n",
    "            frames = self._process_video(video_path)\n",
    "            X[i] = frames.reshape(self.frame_length, self.image_height, self.image_width, 1)\n",
    "            \n",
    "            labels = self._process_alignment(align_path)\n",
    "            Y[i] = tf.reduce_max(tf.one_hot(labels, len(self.vocabulary)), axis=0)\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "\n",
    "def build_model(frame_length, image_height, image_width, vocabulary_size):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(frame_length, image_height, image_width, 1)), \n",
    "        Conv3D(64, kernel_size=(3, 3, 3), activation='relu'),\n",
    "        MaxPool3D(pool_size=(1, 2, 2)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Conv3D(128, kernel_size=(3, 3, 3), activation='relu'),\n",
    "        MaxPool3D(pool_size=(1, 2, 2)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Conv3D(256, kernel_size=(3, 3, 3), activation='relu'),\n",
    "        MaxPool3D(pool_size=(1, 2, 2)),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Reshape((-1, 256)),\n",
    "        \n",
    "        Bidirectional(LSTM(128, return_sequences=True)),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Bidirectional(LSTM(64)),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(vocabulary_size, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_save_main_model(data_dir, alignment_dir, batch_size=32):\n",
    "    print(\"Starting training for sentence-level prediction...\")\n",
    "    \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_dir = f\"models_main_{timestamp}\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    data_generator = LipReadingDataGenerator(data_dir, alignment_dir, batch_size=batch_size)\n",
    "    \n",
    "    model = build_model(\n",
    "        frame_length=75,\n",
    "        image_height=46,\n",
    "        image_width=140,\n",
    "        vocabulary_size=len(data_generator.vocabulary)\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            os.path.join(model_dir, 'lip_reading_main_best.keras'),\n",
    "            save_best_only=True,\n",
    "            monitor='accuracy'\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        TqdmCallback(verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    model.fit(\n",
    "        data_generator,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    final_model_path = os.path.join(model_dir, 'model.h5')\n",
    "    model.save(final_model_path)\n",
    "    print(f\"Final model saved: {final_model_path}\")\n",
    "\n",
    "    vocab_path = os.path.join(model_dir, 'vocabulary_main.txt')\n",
    "    with open(vocab_path, 'w') as f:\n",
    "        f.write('\\n'.join(data_generator.vocabulary))\n",
    "    print(f\"Vocabulary saved: {vocab_path}\")\n",
    "\n",
    "    return model, model_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training main model...\n",
      "Starting training for sentence-level prediction...\n",
      "Found 1000 video files and 1000 alignment files\n",
      "Processing alignment files from: data/alignments/s1\n",
      "Vocabulary size: 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c09d7adb602415ea4ea495212f931ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5326d56796f7429fbe29ab820c05084b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "def predict_with_main_model(model_dir, video_path):\n",
    "    vocab_path = os.path.join(model_dir, 'vocabulary_main.txt')\n",
    "    with open(vocab_path, 'r') as f:\n",
    "        vocabulary = f.read().splitlines()\n",
    "\n",
    "    data_generator = LipReadingDataGenerator(\"\", \"\")\n",
    "    data_generator.vocabulary = vocabulary\n",
    "    data_generator.char_to_num = tf.keras.layers.StringLookup(\n",
    "        vocabulary=vocabulary, oov_token=\"\")\n",
    "    data_generator.num_to_char = tf.keras.layers.StringLookup(\n",
    "        vocabulary=vocabulary, oov_token=\"\", invert=True)\n",
    "\n",
    "    model = load_model(os.path.join(model_dir, 'model.h5'))\n",
    "\n",
    "    frames = data_generator._process_video(video_path)\n",
    "    frames = frames.reshape(1, data_generator.frame_length, \n",
    "                            data_generator.image_height, \n",
    "                            data_generator.image_width, 1)\n",
    "\n",
    "    prediction = model.predict(frames)\n",
    "    predicted_indices = tf.argmax(prediction, axis=1)\n",
    "    predicted_text = data_generator.num_to_char(predicted_indices)\n",
    "\n",
    "    return ' '.join(predicted_text.numpy().decode('utf-8').split())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = r\"data/s1\"\n",
    "    alignment_dir = r\"data/alignments/s1\"\n",
    "\n",
    "    print(\"Training main model...\")\n",
    "    main_model, main_model_dir = train_and_save_main_model(data_dir, alignment_dir)\n",
    "\n",
    "    test_video = r\"data\\s1\\bbaf2n.mpg\"\n",
    "\n",
    "    print(\"\\nMaking predictions...\")\n",
    "    sentence_prediction = predict_with_main_model(main_model_dir, test_video)\n",
    "    print(f\"Predicted sentence: {sentence_prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
